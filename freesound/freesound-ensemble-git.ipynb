{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "%reload_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pdb\n",
    "import bcolz\n",
    "import seaborn as sns\n",
    "import librosa\n",
    "import librosa.display\n",
    "import matplotlib.pyplot as plt\n",
    "import pickle\n",
    "import datetime\n",
    "from fastai.conv_learner import *\n",
    "from fastai.dataset import *\n",
    "from random import shuffle\n",
    "from ipywidgets import widgets\n",
    "from tqdm import tqdm\n",
    "from scipy.io.wavfile import read, write"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "PATH = Path('data/freesound')\n",
    "train_PATH = Path('data/freesound/audio_train')\n",
    "test_PATH = Path('data/freesound/audio_test')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ensembling of results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ResultsDataset(Dataset):\n",
    "    def __init__(self, results_l, targets):\n",
    "        self.results = np.concatenate(results_l, axis=1)\n",
    "        self.targets = targets\n",
    "    \n",
    "    def __len__(self):    \n",
    "        return len(self.results)\n",
    "    \n",
    "    def __getitem__(self, i):\n",
    "        x = self.results[i]\n",
    "        y = self.targets[i]\n",
    "        return x, y\n",
    "    \n",
    "    \n",
    "class EnsembleNet(nn.Module):\n",
    "    def __init__(self, n, c):\n",
    "        super().__init__()\n",
    "        self.features_d = {}\n",
    "        for i in range(n):\n",
    "            setattr(self, f'features_{i}', nn.Sequential(nn.Linear(c,c), nn.Tanh()))\n",
    "            self.features_d[i] = f'features_{i}'\n",
    "        self.n = n\n",
    "        self.c = c\n",
    "                \n",
    "    def forward(self, results):         \n",
    "        c = self.c\n",
    "        n = self.n\n",
    "        ens_d = {}\n",
    "        ens_d[0] = results[:,:c]\n",
    "        m1 = 1; m2 = 2\n",
    "        for i in range(n-2):\n",
    "            ens_d[i+1] = results[:,c*m1:c*m2]\n",
    "            m1 += 1\n",
    "            m2 += 1\n",
    "        ens_d[n-1]= results[:,c*(n-1):]\n",
    "        var_l = []\n",
    "        for i in range(n):    \n",
    "            v = getattr(self, self.features_d[i])(V(ens_d[i].contiguous().cuda(async=True)))\n",
    "            var_l.append(v.unsqueeze(0))\n",
    "        x = torch.cat(var_l, 0)\n",
    "        x = torch.mean(x, 0) * n\n",
    "        return F.softmax(x, dim=-1)\n",
    "    \n",
    "\n",
    "class Ensemble():\n",
    "    def __init__(self, c, classes, ensemble_trn_dl, targets_train, targets_val, PATH):\n",
    "        self.RES_PATH = PATH / 'results'\n",
    "        self.TEST_PATH = PATH / 'test_results'\n",
    "        self.ENS_PATH = PATH / 'ensemble_files'\n",
    "        os.makedirs(self.RES_PATH, exist_ok=True)\n",
    "        os.makedirs(self.TEST_PATH, exist_ok=True)\n",
    "        os.makedirs(self.ENS_PATH, exist_ok=True)\n",
    "        self.c = c\n",
    "        self.classes = classes\n",
    "        self.ensemble_trn_dl = ensemble_trn_dl\n",
    "        self.targets_trn = targets_train\n",
    "        self.targets_val = targets_val\n",
    "         \n",
    "    def add_model(self, learn, mname, mdescription, own_accuracy):\n",
    "        mnames = !ls {str(self.RES_PATH)}\n",
    "        mnames = [f[:len(mname)] for f in mnames]\n",
    "        assert mname not in mnames, 'This mname exists already, please use another name'\n",
    "        \n",
    "        try:\n",
    "            mdescription_d = pickle.load(open(self.ENS_PATH/\"mdescription_d.pickle\", \"rb\"))\n",
    "            mdescription_d[mname] = [mdescription, own_accuracy]\n",
    "            pickle.dump(mdescription_d, open(self.ENS_PATH/\"mdescription_d.pickle\", \"wb\"))\n",
    "\n",
    "        except (OSError, IOError) as e:\n",
    "            mdescription_d = {}\n",
    "            mdescription_d[mname] = [mdescription, own_accuracy] \n",
    "            pickle.dump(mdescription_d, open(self.ENS_PATH/\"mdescription_d.pickle\", \"wb\"))\n",
    "        \n",
    "        learn.data.trn_dl = self.ensemble_trn_dl\n",
    "        results_trn = self.run_model(learn, learn.data.trn_dl)\n",
    "        results_val = self.run_model(learn, learn.data.val_dl)\n",
    "        results_test = self.run_model(learn, learn.data.test_dl)\n",
    "        self.save_results(results_trn, results_val, results_test, mname)\n",
    "            \n",
    "    def add_model_by_using_results(self, mname, mdescription, own_accuracy, results_trn, results_val, results_test):\n",
    "        mnames = !ls {str(self.RES_PATH)}\n",
    "        mnames = [f[:len(mname)] for f in mnames]\n",
    "        assert mname not in mnames, 'This mname exists already, please use another name'\n",
    "        \n",
    "        try:\n",
    "            mdescription_d = pickle.load(open(self.ENS_PATH/\"mdescription_d.pickle\", \"rb\"))\n",
    "            mdescription_d[mname] = [mdescription, own_accuracy]\n",
    "            pickle.dump(mdescription_d, open(self.ENS_PATH/\"mdescription_d.pickle\", \"wb\"))\n",
    "\n",
    "        except (OSError, IOError) as e:\n",
    "            mdescription_d = {}\n",
    "            mdescription_d[mname] = [mdescription, own_accuracy] \n",
    "            pickle.dump(mdescription_d, open(self.ENS_PATH/\"mdescription_d.pickle\", \"wb\"))\n",
    "        \n",
    "        self.save_results(results_trn, results_val, results_test, mname)\n",
    "        \n",
    "    def run_model(self, learn, dl):\n",
    "        results = torch.zeros(1, self.c).cuda()\n",
    "        learn.model.eval()\n",
    "        it = iter(dl)\n",
    "        _next = True\n",
    "        while _next:\n",
    "            try:\n",
    "                x, y = next(it)\n",
    "                probs = learn.model(V(x)).float().exp().data\n",
    "                results = torch.cat((results, probs), dim=0)\n",
    "            except StopIteration:\n",
    "                _next = False\n",
    "        results = results.cpu().numpy()\n",
    "        return results[1:]\n",
    "        \n",
    "    def save_results(self, results_trn, results_val, results_test, mname):\n",
    "        np.save(self.RES_PATH / f'{mname}_trn.npy', results_trn) \n",
    "        np.save(self.RES_PATH / f'{mname}_val.npy', results_val)\n",
    "        np.save(self.TEST_PATH / f'{mname}_test.npy', results_test)\n",
    "        \n",
    "    def ensemble_magic(self, bs, lr, n_epochs, mnames=None, ensemble_ID=None):\n",
    "        if mnames == None and ensemble_ID == None:\n",
    "            raise ValueError('please enter either mnames or ensemble_ID')\n",
    "            \n",
    "        if mnames != None and ensemble_ID != None:\n",
    "            raise ValueError('please enter either mnames or ensemble_ID')\n",
    "                \n",
    "        if mnames is not None:\n",
    "            assert isinstance(mnames, list), 'mnames is not a list, please use a list'\n",
    "            mnames = set(mnames)\n",
    "            existing_mnames = !ls {str(self.RES_PATH)}\n",
    "            existing_mnames = set([f[:-8] for f in existing_mnames])\n",
    "            for mname in mnames:\n",
    "                assert mname in existing_mnames, f'mname {mname} does not exist, please check it'\n",
    "\n",
    "            try:\n",
    "                ensemble_d = pickle.load(open(self.ENS_PATH / \"ensemble_d.pickle\", \"rb\"))\n",
    "                ensemble_ID = self.ensemble_exists(mnames, ensemble_d)\n",
    "                \n",
    "                if ensemble_ID is False:\n",
    "                    ensemble_ID = max(ensemble_d.keys()) + 1\n",
    "                    ensemble_d[ensemble_ID] = mnames\n",
    "                    pickle.dump(ensemble_d, open(self.ENS_PATH / \"ensemble_d.pickle\", \"wb\"))\n",
    "                    self.run_experiment(ensemble_ID, bs, lr, n_epochs)      \n",
    "\n",
    "                else:\n",
    "                    print(f'This ensemble exists already, it\\'s ID is: {ensemble_ID}')\n",
    "                    print('Would you like to run another experiment on this ensemble?')\n",
    "                    button = widgets.Button(description='Yes')    \n",
    "                    display(button)\n",
    "                    button.on_click(lambda b: self.run_experiment(ensemble_ID, bs, lr, n_epochs))\n",
    "                    \n",
    "            except (OSError, IOError) as e:\n",
    "                ensemble_d = {}\n",
    "                ensemble_ID = 0\n",
    "                ensemble_d[ensemble_ID] = mnames\n",
    "                pickle.dump(ensemble_d, open(self.ENS_PATH / \"ensemble_d.pickle\", \"wb\"))\n",
    "                self.run_experiment(ensemble_ID, bs, lr, n_epochs)\n",
    "\n",
    "        else:\n",
    "            self.run_experiment(ensemble_ID, bs, lr, n_epochs)      \n",
    "              \n",
    "    def run_experiment(self, ensemble_ID, bs, lr, n_epochs, model_importance=False):                  \n",
    "        results_l_trn, results_l_val, results_l_test = self.assemble_results(ensemble_ID)\n",
    "        assert len(results_l_trn) == len(results_l_val) == len(results_l_test)\n",
    "        n = len(results_l_trn)\n",
    "        md = self.create_ModelData(results_l_trn, results_l_val, results_l_test, bs)\n",
    "        ens_learn = self.ensemble_network(md, n, lr, n_epochs)\n",
    "        if model_importance == False:\n",
    "            print(\"Would you like to add the experiment to your report?\")    \n",
    "            button = widgets.Button(description='Yes')    \n",
    "            display(button)\n",
    "            button.on_click(lambda b: self.add2report(ens_learn, ensemble_ID))             \n",
    "        else:\n",
    "            return ens_learn   \n",
    "                \n",
    "    def assemble_results(self, ensemble_ID):\n",
    "        ensemble_d = pickle.load(open(self.ENS_PATH / \"ensemble_d.pickle\", \"rb\"))\n",
    "        mnames = ensemble_d[ensemble_ID]\n",
    "        results_l_trn = [np.load(self.RES_PATH / f'{mname}_trn.npy') for mname in mnames]\n",
    "        results_l_val = [np.load(self.RES_PATH / f'{mname}_val.npy') for mname in mnames]\n",
    "        results_l_test = [np.load(self.TEST_PATH / f'{mname}_test.npy') for mname in mnames]\n",
    "        return results_l_trn, results_l_val, results_l_test\n",
    "        \n",
    "    def create_ModelData(self, results_l_trn, results_l_val, results_l_test, bs):\n",
    "        res_trn_ds = ResultsDataset(results_l_trn, self.targets_trn)\n",
    "        res_val_ds = ResultsDataset(results_l_val, self.targets_val)\n",
    "        res_test_ds = ResultsDataset(results_l_test, np.zeros(len(results_l_test[0])))\n",
    "        trn_dl = DataLoader(res_trn_ds, bs)\n",
    "        val_dl = DataLoader(res_val_ds, bs)\n",
    "        test_dl = DataLoader(res_test_ds, bs)\n",
    "        return ModelData(self.ENS_PATH, trn_dl, val_dl, test_dl)\n",
    "        \n",
    "    def ensemble_network(self, md, n, lr, n_epochs):\n",
    "        ens = EnsembleNet(n, self.c).cuda()\n",
    "        crit = nn.NLLLoss()\n",
    "        metrics =[accuracy]\n",
    "        torch.backends.cudnn.benchmark=True\n",
    "        ens_learn = Learner(md, SingleModel(ens), opt_fn=optim.Adam, metrics=metrics, crit=crit)\n",
    "        ens_learn.fit(lr, n_epochs)\n",
    "        return ens_learn\n",
    "    \n",
    "    def add2report(self, ens_learn, ensemble_ID):\n",
    "        results = self.run_model(ens_learn, ens_learn.data.val_dl)\n",
    "        ensemble_d = pickle.load(open(self.ENS_PATH / \"ensemble_d.pickle\", \"rb\"))\n",
    "        mnames_all = [v for v in ensemble_d.values()]  \n",
    "        mnames_all = set([item for sublist in mnames_all for item in sublist])\n",
    "        mnames = ensemble_d[ensemble_ID]\n",
    "        row_df = pd.DataFrame(index=[0], columns=['accuracy', 'datetime', 'ensemble_ID', 'mapk'])\n",
    "        row_df['ensemble_ID'] = ensemble_ID\n",
    "        now = datetime.datetime.now()\n",
    "        row_df['datetime'] =str(now.strftime(\"%Y-%m-%d %H:%M\"))\n",
    "        row_df['accuracy'] = self.accuracy(results, self.targets_val)\n",
    "        row_df['mapk'] = self.mapk_score(results, self.targets_val)\n",
    "\n",
    "        try:\n",
    "            ensemble_df = pd.read_feather(self.ENS_PATH / 'ensemble_df')\n",
    "            ensemble_df = pd.concat([row_df, ensemble_df])\n",
    "            ensemble_df = ensemble_df.reset_index().drop(['index'], axis=1)\n",
    "            ensemble_df.to_feather(self.ENS_PATH / 'ensemble_df')\n",
    "            print(ensemble_df)\n",
    "\n",
    "        except (OSError, IOError) as e:\n",
    "            row_df.to_feather(self.ENS_PATH / 'ensemble_df')\n",
    "            print(row_df)\n",
    "\n",
    "        print(\"\\n\"'''Save ens_learn? Save ens_learn only if you want to run \n",
    "ensemble predictions to create a submission file.''')      \n",
    "        button = widgets.Button(description='Yes')\n",
    "        display(button)\n",
    "        button.on_click(lambda b: self.save_ens_learn(ens_learn, ensemble_ID))\n",
    "            \n",
    "    def save_ens_learn(self, ens_learn, ensemble_ID):\n",
    "        name = f'ens_learn_{ensemble_ID}.pkl'\n",
    "        existing_names = !ls {str(self.ENS_PATH)}\n",
    "        if name in existing_names:\n",
    "            print('''An ens_learn object for this ensemble exists already, \n",
    "would you like to replace it?''')\n",
    "            button = widgets.Button(description='Yes')\n",
    "            display(button)\n",
    "            button.on_click(lambda b: pickle.dump(ens_learn, open(self.ENS_PATH / name, 'wb')))            \n",
    "        else:                         \n",
    "            pickle.dump(ens_learn, open(self.ENS_PATH / name, 'wb'))\n",
    "        \n",
    "    def ensemble_exists(self, mnames, ensemble_d):\n",
    "        ensembles = [(k,v) for k,v in ensemble_d.items()]  \n",
    "        for k,v in ensembles:\n",
    "            if v == mnames:\n",
    "                return k \n",
    "        return False\n",
    "             \n",
    "    def accuracy(self, results, targets):\n",
    "        idxs = np.argmax(results, axis=1)\n",
    "        return np.where(idxs==targets, 1, 0).sum() / len(results)\n",
    "    \n",
    "    def apk(self, actual, predicted, k=10):\n",
    "        if len(predicted)>k:\n",
    "            predicted = predicted[:k]\n",
    "        score = 0.0\n",
    "        num_hits = 0.0\n",
    "        for i,p in enumerate(predicted):\n",
    "            if p in actual and p not in predicted[:i]:\n",
    "                num_hits += 1.0\n",
    "                score += num_hits / (i+1.0)\n",
    "\n",
    "        if not actual:\n",
    "            return 0.0\n",
    "\n",
    "        return score / min(len(actual), k)\n",
    "\n",
    "    def mapk(self, actual, predicted, k=10):\n",
    "        return np.mean([self.apk(a,p,k) for a,p in zip(actual, predicted)])\n",
    "\n",
    "    def mapk_score(self, results, targets):\n",
    "        predictions = [list(np.argsort(results[i])[::-1][:3]) for i in range(len(results))]\n",
    "        actual = [[i] for i in targets]\n",
    "        return self.mapk(actual, predictions, k=3)\n",
    "        \n",
    "    def view_report(self):\n",
    "        try:\n",
    "            ensemble_df = pd.read_feather(self.ENS_PATH / 'ensemble_df')\n",
    "            print(ensemble_df)\n",
    "        except (OSError, IOError) as e:\n",
    "            print('Report can be displayed when you have created an ensemble')\n",
    "    \n",
    "    def view_model_descriptions(self):\n",
    "        try:\n",
    "            mdescription_d = pickle.load(open(self.ENS_PATH / \"mdescription_d.pickle\", \"rb\"))\n",
    "            desc_df = pd.DataFrame.from_dict(mdescription_d, orient='index')\n",
    "            desc_df.columns = ['Description', 'Accuracy']\n",
    "            print(desc_df)\n",
    "        except (OSError, IOError) as e:\n",
    "            print('No models have been added yet')\n",
    "    \n",
    "    def create_submission(self, ensemble_ID, name):\n",
    "        ens_learn_name = f'ens_learn_{ensemble_ID}.pkl'\n",
    "        existing_ens_learn_names = !ls {str(self.ENS_PATH)}\n",
    "        assert ens_learn_name in existing_ens_learn_names, '''An ens_learn object for this \n",
    "ensemble does not exist. Please remember to save ens_learn after you have added an \n",
    "experiment to the report.'''\n",
    "        ens_learn = pickle.load(open(self.ENS_PATH/f'ens_learn_{ensemble_ID}.pkl', \"rb\"))\n",
    "        predictions = self.run_model(ens_learn, ens_learn.data.test_dl)\n",
    "        predictions = self.preds_to_labels(predictions, self.classes)\n",
    "        self.create_submission_file(predictions, name)\n",
    "        \n",
    "    def preds_to_labels(self, p, labels):\n",
    "        predictions = [list(np.argsort(p[i])[::-1][:3]) for i in range(len(p))]\n",
    "        prediction_labels = []\n",
    "\n",
    "        for pred in predictions:\n",
    "            label_list = []\n",
    "            for output in pred:\n",
    "                label_list.append(labels[output])\n",
    "            prediction_labels.append(label_list)\n",
    "        return prediction_labels\n",
    "\n",
    "    def create_submission_file(self, predictions, name):\n",
    "        predictions = ['{} {} {}'.format(x[0], x[1], x[2]) for x in predictions]\n",
    "        submission = pd.read_csv(PATH/'sample_submission_no_bads.csv')\n",
    "        submission.label = predictions\n",
    "        submission.to_csv(f'{self.ENS_PATH}/{name}', index=False)\n",
    "        print(f'Submission saved to {self.ENS_PATH/name}')    \n",
    "        \n",
    "    def model_importance(self, ensemble_ID, bs, lr, n_epochs):\n",
    "        ens_learn = self.run_experiment(ensemble_ID, bs, lr, n_epochs, model_importance=True)     \n",
    "        results = self.run_model(ens_learn, ens_learn.data.val_dl)\n",
    "        accuracy_all = self.accuracy(results, self.targets_val)\n",
    "        mapk_all = self.mapk_score(results, self.targets_val)\n",
    "        ensemble_IDs = self.complement_ensemble(ensemble_ID)\n",
    "        model_importance_d = {}\n",
    " \n",
    "        for i in ensemble_IDs:\n",
    "            print('')\n",
    "            print(f'ensemble_ID: {i}')\n",
    "            ens_learn = self.run_experiment(i, bs, lr, n_epochs, model_importance=True)     \n",
    "            results = self.run_model(ens_learn, ens_learn.data.val_dl)\n",
    "            accuracy = self.accuracy(results, self.targets_val)\n",
    "            mapk = self.mapk_score(results, self.targets_val)\n",
    "            model_importance_d[i] = [accuracy_all-accuracy, mapk_all-mapk] \n",
    "            \n",
    "        ID_to_removed_model_d = {}\n",
    "        for i in model_importance_d:\n",
    "            model = self.removed_model(ensemble_ID, i)\n",
    "            ID_to_removed_model_d[i] = model \n",
    "  \n",
    "        model_importance_df = pd.DataFrame.from_dict(model_importance_d, orient='index').reset_index(drop=True)\n",
    "        model_importance_df.columns = ['accuracy', 'mapk']\n",
    "        model_importance_df['model'] = model_importance_d.keys()\n",
    "        model_importance_df['model'] = model_importance_df['model'].map(ID_to_removed_model_d)\n",
    "        model_importance_df.sort_values(by=['accuracy'], ascending=False, inplace=True)\n",
    "        print(model_importance_df)\n",
    "\n",
    "    def removed_model(self, ensemble_ID, comparison_ID):\n",
    "        ensemble_d = pickle.load(open(self.ENS_PATH / \"ensemble_d.pickle\", \"rb\"))\n",
    "        base_s = ensemble_d[ensemble_ID]\n",
    "        one_removed_s = ensemble_d[comparison_ID]\n",
    "        return base_s.difference(one_removed_s)\n",
    "            \n",
    "    def complement_ensemble(self, ensemble_ID):\n",
    "        ensemble_d = pickle.load(open(self.ENS_PATH / \"ensemble_d.pickle\", \"rb\"))\n",
    "        model_s = ensemble_d[ensemble_ID]\n",
    "        one_model_removed_sets = self.create_one_model_removed_sets(model_s)\n",
    "        existing_sets = [ensemble_d[i] for i in ensemble_d]\n",
    "        complement_sets = [i for i in one_model_removed_sets if i not in existing_sets] \n",
    "        for i in complement_sets:\n",
    "            ensemble_ID = max(ensemble_d.keys()) + 1\n",
    "            ensemble_d[ensemble_ID] = i\n",
    "        \n",
    "        ensemble_IDs = [i for i in ensemble_d if ensemble_d[i] in one_model_removed_sets]\n",
    "        pickle.dump(ensemble_d, open(self.ENS_PATH / \"ensemble_d.pickle\", \"wb\"))\n",
    "        return ensemble_IDs\n",
    "\n",
    "    def create_one_model_removed_sets(self, model_s):\n",
    "        model_s = list(model_s)\n",
    "        one_removed_sets = []\n",
    "        for i in range(len(model_s)):\n",
    "            one_removed_sets.append(set(model_s[i:] + model_s[:i-1]))\n",
    "        return one_removed_sets[1:]\n",
    "    \n",
    "    def view_models_in_ensemble(self, ensemble_ID):\n",
    "        ensemble_d = pickle.load(open(self.ENS_PATH / \"ensemble_d.pickle\", \"rb\"))\n",
    "        return ensemble_d[ensemble_ID]\n",
    "    \n",
    "    def view_sorted_model_descriptions(self):\n",
    "        try:\n",
    "            mdescription_d = pickle.load(open(self.ENS_PATH / \"mdescription_d.pickle\", \"rb\"))\n",
    "            desc_df = pd.DataFrame.from_dict(mdescription_d, orient='index')\n",
    "            desc_df.columns = ['Description', 'Accuracy']\n",
    "            desc_df.sort_values(by=['Accuracy'], ascending=False, inplace=True)\n",
    "            return desc_df\n",
    "        except (OSError, IOError) as e:\n",
    "            print('No models have been added yet')\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create an instance of class Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {},
   "outputs": [],
   "source": [
    "c = 41\n",
    "targets_train = split_df.iloc[ensemble_train_idxs].label.values\n",
    "targets_val = split_df.iloc[val_split_idxs].label.values\n",
    "PATH = Path('data/freesound')\n",
    "freesound_ensemble = Ensemble(c, classes, ensemble_trn_dl, targets_train, targets_val, PATH) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Add a model to your pool of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = 'r31'\n",
    "mdescription = 'resnet trained on random training set without weight decay'\n",
    "own_accuracy = '0.64'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "How ensembling works:\n",
    "- 'c' is the number of target categories \n",
    "- training and validation dataloaders concatenate the training and validation results of the models in the ensemble to load the data as training and validation minibatches (batch size x (c * number of models)) to a neural network\n",
    "- the neural network unconcatenates the results in each minibatch and matrix multiplies each bit (batch size x c) with a linear layer of size 'c'\n",
    "- the neural network adds the resulting activations together and softmaxes the result\n",
    "- a negative log loss function is used in optimizing the network \n",
    "\n",
    "Hence, you must always use the same training and validation sets when adding models to your model pool."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add a new fast.ai model to your model pool"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [],
   "source": [
    "freesound_ensemble.add_model(learn, mname, mdescription, own_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Add a new model by using training, validation and test results (numpy arrays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [],
   "source": [
    "mname = 'catboost'\n",
    "mdescription = 'catboost'\n",
    "own_accuracy = '0.75'\n",
    "results_trn = np.load(PATH/'catboost_train.npy')\n",
    "results_val = np.load(PATH/'catboost_val.npy')\n",
    "results_test = np.load(PATH/'catboost_test.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 483,
   "metadata": {},
   "outputs": [],
   "source": [
    "freesound_ensemble.add_model_by_using_results(mname, mdescription, own_accuracy, results_trn, results_val, results_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View model descriptions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                                               Description Accuracy\n",
      "r_2      resnet trained on random training set with wei...     0.67\n",
      "r_4      resnet trained on random training set with wei...     0.65\n",
      "r_5      resnet trained on ensemble training set with w...     0.67\n",
      "r_6      resnet trained on mix of training sets with we...     0.67\n",
      "r_7      resnet trained on mix of training sets with we...     0.67\n",
      "r_10     resnet trained on mix of training sets with we...     0.68\n",
      "r_15     resnet trained on random training set with wei...     0.68\n",
      "r_18     resnet trained on random training set with wei...     0.69\n",
      "r_22     resnet trained on random training set with wei...     0.66\n",
      "r_26     resnet trained on random training set with wei...     0.65\n",
      "r_30     resnet trained on random training set with wei...     0.65\n",
      "r34_3    resnet34 trained on random training set with w...     0.71\n",
      "r34_5    resnet34 trained on random training set withou...     0.74\n",
      "r34_6    resnet34 trained on random training set with w...     0.68\n",
      "r34_7    resnet34 trained on random training set with a...     0.72\n",
      "r34_8    resnet34 trained on ensemble training set with...     0.73\n",
      "r34_10   resnet34 trained on random training set withou...     0.76\n",
      "r34_11   unfrozen resnet34 trained on random training s...     0.74\n",
      "r34_12   unfrozen resnet34 trained on random training s...     0.65\n",
      "r34_14   unfrozen resnet34 trained on random training s...     0.76\n",
      "r34_15   unfrozen resnet34 trained on random training s...     0.74\n",
      "r101_2   pretrained resnet101 trained on random trainin...     0.67\n",
      "r_33     pretrained resnet34 trained on random training...     0.75\n",
      "rx_2     pretrained resnext101 trained on random traini...     0.73\n",
      "rx_3     pretrained resnext101 trained on random traini...     0.70\n",
      "rx_5     pretrained resnext101 with original classifier...     0.77\n",
      "rx_7     pretrained resnext101 with original classifier...     0.75\n",
      "rx_9     unfrozen resnext101 with original classifier t...     0.76\n",
      "rx_11    unfrozen resnext101 with original classifier t...     0.72\n",
      "rx_13    unfrozen resnext101 with original classifier t...     0.75\n",
      "alex_6   frozen and then unfrozen alexnet trained on ra...     0.67\n",
      "alex_16  frozen and then unfrozen alexnet trained on ra...     0.69\n",
      "r_raw_1    resnet trained on raw data without weight decay     0.66\n",
      "lgbm                                                  lgbm     0.77\n",
      "xbg_1                                                  xgb     0.63\n",
      "xbg_2                                                  xgb     0.63\n",
      "xbg_3                                                  xgb     0.63\n",
      "rb_1     resnet trained on binarized spectagram data, r...     0.54\n",
      "rb_2     resnet trained on binarized spectagram data, r...     0.54\n",
      "rb_3     resnet trained on binarized spectagram data, r...     0.54\n",
      "r34b_1   resnet34 trained on binarized spectagram data,...     0.65\n",
      "r31      resnet trained on random training set without ...     0.64\n",
      "r34b_2   resnet34 trained on binarized spectagram data,...     0.64\n",
      "r34ev_3  resnet34 trained on sound event spectagram dat...     0.71\n"
     ]
    }
   ],
   "source": [
    "freesound_ensemble.view_model_descriptions()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model descriptions shorted by descending accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 496,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['lgbm', 'rx_5', 'r34_10', 'rx_9', 'r34_14', 'r_33', 'rx_13', 'rx_7',\n",
       "       'catboost', 'r34_5', 'r34_11', 'r34_15', 'r34_8', 'rx_2', 'r34_7',\n",
       "       'rx_11', 'r34_3', 'r34ev_3', 'rx_3', 'r_18', 'alex_16', 'r_15', 'r34_6',\n",
       "       'r_10', 'r_7', 'r_5', 'alex_6', 'r_6', 'r_2', 'r101_2', 'r_raw_1',\n",
       "       'r_22', 'r_30', 'r_4', 'r34_12', 'r34b_1', 'r_26', 'r31', 'r34b_2',\n",
       "       'xbg_1', 'xbg_2', 'xbg_3', 'rb_1', 'rb_2', 'rb_3'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 496,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "desc_df = freesound_ensemble.view_sorted_model_descriptions()\n",
    "desc_df.index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Try out an ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 521,
   "metadata": {},
   "outputs": [],
   "source": [
    "bs = 56; lr = 0.003; n_epochs = 3\n",
    "mnames = ['alex_16', 'catboost', 'xbg_3',\n",
    " 'alex_6',\n",
    " 'lgbm',\n",
    " 'r34_10',\n",
    " 'r34_15',\n",
    " 'r34_5',\n",
    " 'r_10',\n",
    " 'r_22',\n",
    " 'r_raw_1',\n",
    " 'rx_13',\n",
    " 'rx_5',\n",
    " 'rx_7',\n",
    " 'rx_9']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 529,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "This ensemble exists already, it's ID is: 569\n",
      "Would you like to run another experiment on this ensemble?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7c7e2251e3e4423aa7f2dbb3219afb73",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Yes', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "189b7eaab70f47499c1f7d98dac08666",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.810172  -0.703729  0.812015  \n",
      "    1      -0.969878  -0.744093  0.817193                      \n",
      "    2      -0.9877    -0.757917  0.819265                      \n",
      "Would you like to add the experiment to your report?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "c78012d690014f1888d5166659e4494c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Yes', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    accuracy          datetime  ensemble_ID      mapk\n",
      "0   0.819265  2018-07-04 19:42          569  0.860953\n",
      "1   0.818747  2018-07-04 19:31          569  0.862765\n",
      "2   0.814604  2018-07-04 15:54          461  0.858795\n",
      "3   0.812532  2018-07-04 15:52          461  0.855688\n",
      "4   0.801139  2018-07-04 15:44          558  0.849991\n",
      "5   0.816157  2018-07-04 15:23          461  0.860608\n",
      "6   0.811497  2018-07-04 15:22          461  0.855602\n",
      "7   0.812532  2018-07-04 15:22          461  0.856465\n",
      "8   0.811497  2018-07-04 15:21          445  0.856033\n",
      "9   0.810979  2018-07-04 15:16          498  0.856810\n",
      "10  0.813050  2018-07-04 13:52          467  0.855774\n",
      "11  0.811497  2018-07-04 13:41          466  0.856119\n",
      "12  0.812015  2018-07-04 13:41          466  0.856637\n",
      "13  0.812015  2018-07-04 13:31          465  0.856119\n",
      "14  0.810979  2018-07-04 13:18          464  0.856810\n",
      "15  0.810461  2018-07-04 13:11          461  0.856551\n",
      "16  0.815122  2018-07-04 08:48          461  0.859313\n",
      "17  0.812532  2018-07-03 14:43          414  0.855688\n",
      "18  0.806318  2018-07-03 14:36          385  0.851890\n",
      "19  0.807354  2018-07-03 13:57          361  0.852494\n",
      "20  0.805800  2018-07-03 13:57          361  0.850682\n",
      "21  0.805282  2018-07-03 13:57          361  0.851286\n",
      "22  0.805282  2018-07-03 13:56          361  0.849301\n",
      "23  0.803211  2018-07-03 13:56          361  0.848610\n",
      "24  0.806318  2018-07-03 13:56          361  0.850337\n",
      "25  0.808907  2018-07-03 13:56          361  0.849991\n",
      "26  0.807354  2018-07-03 13:52          361  0.850423\n",
      "27  0.805282  2018-07-03 13:31          361  0.849387\n",
      "28  0.804764  2018-07-03 13:30          361  0.850337\n",
      "29  0.807872  2018-07-03 13:17          361  0.852408\n",
      "..       ...               ...          ...       ...\n",
      "61  0.764371  2018-07-02 08:50           29  0.812791\n",
      "62  0.763335  2018-07-02 08:42           28  0.809511\n",
      "63  0.759710  2018-07-02 08:42           28  0.809511\n",
      "64  0.758156  2018-07-02 08:22           27  0.808648\n",
      "65  0.751942  2018-07-02 08:21           27  0.803211\n",
      "66  0.755567  2018-07-01 18:09           26  0.809166\n",
      "67  0.756085  2018-07-01 18:02           26  0.808389\n",
      "68  0.757121  2018-07-01 18:01           26  0.809339\n",
      "69  0.751942  2018-07-01 09:09           12  0.802348\n",
      "70  0.750906  2018-07-01 09:08           12  0.803211\n",
      "71  0.750388  2018-06-29 16:39           11  0.800621\n",
      "72  0.751424  2018-06-29 16:37           11  0.799586\n",
      "73  0.736924  2018-06-29 16:26           10  0.790696\n",
      "74  0.730192  2018-06-29 16:13            9  0.784568\n",
      "75  0.728638  2018-06-29 16:12            9  0.782669\n",
      "76  0.729156  2018-06-29 16:12            9  0.783100\n",
      "77  0.723459  2018-06-29 16:01            8  0.782669\n",
      "78  0.722941  2018-06-29 16:00            8  0.770499\n",
      "79  0.727602  2018-06-29 15:51            7  0.773779\n",
      "80  0.723977  2018-06-29 14:14            6  0.769204\n",
      "81  0.722424  2018-06-29 14:12            6  0.765407\n",
      "82  0.725013  2018-06-29 13:46            6  0.769204\n",
      "83  0.724495  2018-06-29 13:30            5  0.765234\n",
      "84  0.720352  2018-06-29 13:27            5  0.759969\n",
      "85  0.723977  2018-06-29 13:15            4  0.765752\n",
      "86  0.719834  2018-06-29 13:14            4  0.760314\n",
      "87  0.710513  2018-06-29 13:01            3  0.760573\n",
      "88  0.706888  2018-06-29 13:00            3  0.758415\n",
      "89  0.699637  2018-06-29 12:51            2  0.752374\n",
      "90  0.698602  2018-06-29 12:43            0  0.747281\n",
      "\n",
      "[91 rows x 4 columns]\n",
      "\n",
      "Save ens_learn? Save ens_learn only if you want to run \n",
      "ensemble predictions to create a submission file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "514ba7f0549b429fa517d2b0441cb19d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Yes', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freesound_ensemble.ensemble_magic(bs, lr, n_epochs, mnames)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 478,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "19678a39558d498693a86100a2babcaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.787297  -0.696785  0.809425  \n",
      "    1      -0.965889  -0.740519  0.814604                      \n",
      "    2      -0.985863  -0.754741  0.814604                      \n",
      "Would you like to add the experiment to your report?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b13a61e7626f463283929de8154ca91f",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Yes', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    accuracy          datetime  ensemble_ID      mapk\n",
      "0   0.814604  2018-07-04 15:54          461  0.858795\n",
      "1   0.812532  2018-07-04 15:52          461  0.855688\n",
      "2   0.801139  2018-07-04 15:44          558  0.849991\n",
      "3   0.816157  2018-07-04 15:23          461  0.860608\n",
      "4   0.811497  2018-07-04 15:22          461  0.855602\n",
      "5   0.812532  2018-07-04 15:22          461  0.856465\n",
      "6   0.811497  2018-07-04 15:21          445  0.856033\n",
      "7   0.810979  2018-07-04 15:16          498  0.856810\n",
      "8   0.813050  2018-07-04 13:52          467  0.855774\n",
      "9   0.811497  2018-07-04 13:41          466  0.856119\n",
      "10  0.812015  2018-07-04 13:41          466  0.856637\n",
      "11  0.812015  2018-07-04 13:31          465  0.856119\n",
      "12  0.810979  2018-07-04 13:18          464  0.856810\n",
      "13  0.810461  2018-07-04 13:11          461  0.856551\n",
      "14  0.815122  2018-07-04 08:48          461  0.859313\n",
      "15  0.812532  2018-07-03 14:43          414  0.855688\n",
      "16  0.806318  2018-07-03 14:36          385  0.851890\n",
      "17  0.807354  2018-07-03 13:57          361  0.852494\n",
      "18  0.805800  2018-07-03 13:57          361  0.850682\n",
      "19  0.805282  2018-07-03 13:57          361  0.851286\n",
      "20  0.805282  2018-07-03 13:56          361  0.849301\n",
      "21  0.803211  2018-07-03 13:56          361  0.848610\n",
      "22  0.806318  2018-07-03 13:56          361  0.850337\n",
      "23  0.808907  2018-07-03 13:56          361  0.849991\n",
      "24  0.807354  2018-07-03 13:52          361  0.850423\n",
      "25  0.805282  2018-07-03 13:31          361  0.849387\n",
      "26  0.804764  2018-07-03 13:30          361  0.850337\n",
      "27  0.807872  2018-07-03 13:17          361  0.852408\n",
      "28  0.806836  2018-07-03 13:16          361  0.850596\n",
      "29  0.807354  2018-07-03 13:02          361  0.851631\n",
      "..       ...               ...          ...       ...\n",
      "59  0.764371  2018-07-02 08:50           29  0.812791\n",
      "60  0.763335  2018-07-02 08:42           28  0.809511\n",
      "61  0.759710  2018-07-02 08:42           28  0.809511\n",
      "62  0.758156  2018-07-02 08:22           27  0.808648\n",
      "63  0.751942  2018-07-02 08:21           27  0.803211\n",
      "64  0.755567  2018-07-01 18:09           26  0.809166\n",
      "65  0.756085  2018-07-01 18:02           26  0.808389\n",
      "66  0.757121  2018-07-01 18:01           26  0.809339\n",
      "67  0.751942  2018-07-01 09:09           12  0.802348\n",
      "68  0.750906  2018-07-01 09:08           12  0.803211\n",
      "69  0.750388  2018-06-29 16:39           11  0.800621\n",
      "70  0.751424  2018-06-29 16:37           11  0.799586\n",
      "71  0.736924  2018-06-29 16:26           10  0.790696\n",
      "72  0.730192  2018-06-29 16:13            9  0.784568\n",
      "73  0.728638  2018-06-29 16:12            9  0.782669\n",
      "74  0.729156  2018-06-29 16:12            9  0.783100\n",
      "75  0.723459  2018-06-29 16:01            8  0.782669\n",
      "76  0.722941  2018-06-29 16:00            8  0.770499\n",
      "77  0.727602  2018-06-29 15:51            7  0.773779\n",
      "78  0.723977  2018-06-29 14:14            6  0.769204\n",
      "79  0.722424  2018-06-29 14:12            6  0.765407\n",
      "80  0.725013  2018-06-29 13:46            6  0.769204\n",
      "81  0.724495  2018-06-29 13:30            5  0.765234\n",
      "82  0.720352  2018-06-29 13:27            5  0.759969\n",
      "83  0.723977  2018-06-29 13:15            4  0.765752\n",
      "84  0.719834  2018-06-29 13:14            4  0.760314\n",
      "85  0.710513  2018-06-29 13:01            3  0.760573\n",
      "86  0.706888  2018-06-29 13:00            3  0.758415\n",
      "87  0.699637  2018-06-29 12:51            2  0.752374\n",
      "88  0.698602  2018-06-29 12:43            0  0.747281\n",
      "\n",
      "[89 rows x 4 columns]\n",
      "\n",
      "Save ens_learn? Save ens_learn only if you want to run \n",
      "ensemble predictions to create a submission file.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f3ab7174a4614f9cbc80719a733807d4",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Yes', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An ens_learn object for this ensemble exists already, \n",
      "would you like to replace it?\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37ebd88a0d844f5c9a17c48b7e6223dd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Button(description='Yes', style=ButtonStyle())"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "freesound_ensemble.ensemble_magic(bs, lr, n_epochs, ensemble_ID=461)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "freesound_ensemble.add2report."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    accuracy          datetime  ensemble_ID      mapk\n",
      "0   0.818747  2018-07-04 19:31          569  0.862765\n",
      "1   0.814604  2018-07-04 15:54          461  0.858795\n",
      "2   0.812532  2018-07-04 15:52          461  0.855688\n",
      "3   0.801139  2018-07-04 15:44          558  0.849991\n",
      "4   0.816157  2018-07-04 15:23          461  0.860608\n",
      "5   0.811497  2018-07-04 15:22          461  0.855602\n",
      "6   0.812532  2018-07-04 15:22          461  0.856465\n",
      "7   0.811497  2018-07-04 15:21          445  0.856033\n",
      "8   0.810979  2018-07-04 15:16          498  0.856810\n",
      "9   0.813050  2018-07-04 13:52          467  0.855774\n",
      "10  0.811497  2018-07-04 13:41          466  0.856119\n",
      "11  0.812015  2018-07-04 13:41          466  0.856637\n",
      "12  0.812015  2018-07-04 13:31          465  0.856119\n",
      "13  0.810979  2018-07-04 13:18          464  0.856810\n",
      "14  0.810461  2018-07-04 13:11          461  0.856551\n",
      "15  0.815122  2018-07-04 08:48          461  0.859313\n",
      "16  0.812532  2018-07-03 14:43          414  0.855688\n",
      "17  0.806318  2018-07-03 14:36          385  0.851890\n",
      "18  0.807354  2018-07-03 13:57          361  0.852494\n",
      "19  0.805800  2018-07-03 13:57          361  0.850682\n",
      "20  0.805282  2018-07-03 13:57          361  0.851286\n",
      "21  0.805282  2018-07-03 13:56          361  0.849301\n",
      "22  0.803211  2018-07-03 13:56          361  0.848610\n",
      "23  0.806318  2018-07-03 13:56          361  0.850337\n",
      "24  0.808907  2018-07-03 13:56          361  0.849991\n",
      "25  0.807354  2018-07-03 13:52          361  0.850423\n",
      "26  0.805282  2018-07-03 13:31          361  0.849387\n",
      "27  0.804764  2018-07-03 13:30          361  0.850337\n",
      "28  0.807872  2018-07-03 13:17          361  0.852408\n",
      "29  0.806836  2018-07-03 13:16          361  0.850596\n",
      "..       ...               ...          ...       ...\n",
      "60  0.764371  2018-07-02 08:50           29  0.812791\n",
      "61  0.763335  2018-07-02 08:42           28  0.809511\n",
      "62  0.759710  2018-07-02 08:42           28  0.809511\n",
      "63  0.758156  2018-07-02 08:22           27  0.808648\n",
      "64  0.751942  2018-07-02 08:21           27  0.803211\n",
      "65  0.755567  2018-07-01 18:09           26  0.809166\n",
      "66  0.756085  2018-07-01 18:02           26  0.808389\n",
      "67  0.757121  2018-07-01 18:01           26  0.809339\n",
      "68  0.751942  2018-07-01 09:09           12  0.802348\n",
      "69  0.750906  2018-07-01 09:08           12  0.803211\n",
      "70  0.750388  2018-06-29 16:39           11  0.800621\n",
      "71  0.751424  2018-06-29 16:37           11  0.799586\n",
      "72  0.736924  2018-06-29 16:26           10  0.790696\n",
      "73  0.730192  2018-06-29 16:13            9  0.784568\n",
      "74  0.728638  2018-06-29 16:12            9  0.782669\n",
      "75  0.729156  2018-06-29 16:12            9  0.783100\n",
      "76  0.723459  2018-06-29 16:01            8  0.782669\n",
      "77  0.722941  2018-06-29 16:00            8  0.770499\n",
      "78  0.727602  2018-06-29 15:51            7  0.773779\n",
      "79  0.723977  2018-06-29 14:14            6  0.769204\n",
      "80  0.722424  2018-06-29 14:12            6  0.765407\n",
      "81  0.725013  2018-06-29 13:46            6  0.769204\n",
      "82  0.724495  2018-06-29 13:30            5  0.765234\n",
      "83  0.720352  2018-06-29 13:27            5  0.759969\n",
      "84  0.723977  2018-06-29 13:15            4  0.765752\n",
      "85  0.719834  2018-06-29 13:14            4  0.760314\n",
      "86  0.710513  2018-06-29 13:01            3  0.760573\n",
      "87  0.706888  2018-06-29 13:00            3  0.758415\n",
      "88  0.699637  2018-06-29 12:51            2  0.752374\n",
      "89  0.698602  2018-06-29 12:43            0  0.747281\n",
      "\n",
      "[90 rows x 4 columns]\n"
     ]
    }
   ],
   "source": [
    "freesound_ensemble.view_report()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model importance report"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model importance is calculated as the difference of accuracy / mapk when a single model is removed from an ensemble. The report calculates model importance for all models included in the ensemble passed in. The report is sorted according to descending accuracy importance.    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 394,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_ID = 545\n",
    "bs = 56; lr = 0.0041; n_epochs = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e8c06b2f7be430eb8b9e6beb00afa1b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.789506  -0.708914  0.815122  \n",
      "    1      -0.959631  -0.75136   0.816675                      \n",
      "    2      -0.980802  -0.764941  0.817711                      \n",
      "\n",
      "ensemble_ID: 548\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7077991a43d54582874196ffb56ba0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.757449  -0.690187  0.812532  \n",
      "    1      -0.955858  -0.740928  0.816157                      \n",
      "    2      -0.980167  -0.756487  0.819265                     \n",
      "\n",
      "ensemble_ID: 549\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b0c9e4677d2440b083763e2cedd8b0d0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.765674  -0.693531  0.81564   \n",
      "    1      -0.956815  -0.742264  0.817193                      \n",
      "    2      -0.980198  -0.757527  0.8203                       \n",
      "\n",
      "ensemble_ID: 550\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "aef58f419f12487ea88444bb273f9eb3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.752454  -0.691728  0.814086  \n",
      "    1      -0.950924  -0.74179   0.818229                      \n",
      "    2      -0.97629   -0.757229  0.819265                      \n",
      "\n",
      "ensemble_ID: 551\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e9a9ae8bb307485b98f749f195e523bd",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.760953  -0.703146  0.811497  \n",
      "    1      -0.956017  -0.749335  0.815122                      \n",
      "    2      -0.979463  -0.763239  0.81564                      \n",
      "\n",
      "ensemble_ID: 552\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "33fd0f027b214acc9b99739ac07beeaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.75224   -0.699729  0.814604  \n",
      "    1      -0.952021  -0.747141  0.814604                      \n",
      "    2      -0.976993  -0.761379  0.816675                      \n",
      "\n",
      "ensemble_ID: 553\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "37b36a8bb9784313afacb713939e2200",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.753448  -0.692553  0.815122  \n",
      "    1      -0.95244   -0.74332   0.816157                      \n",
      "    2      -0.977616  -0.758766  0.816675                      \n",
      "\n",
      "ensemble_ID: 554\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "1714611c336d4607937df01b1a04e50e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.745251  -0.69793   0.813568  \n",
      "    1      -0.950298  -0.748181  0.818747                      \n",
      "    2      -0.976158  -0.763044  0.820818                      \n",
      "\n",
      "ensemble_ID: 555\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "10ba25fdca4c45498fbd8405cd803923",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.764093  -0.695425  0.818229  \n",
      "    1      -0.957092  -0.744584  0.820818                      \n",
      "    2      -0.980518  -0.759837  0.822372                      \n",
      "\n",
      "ensemble_ID: 556\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "569e3a157cf64e688b65d6ad51cd611d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.746298  -0.688079  0.81564   \n",
      "    1      -0.949764  -0.740583  0.815122                      \n",
      "    2      -0.97586   -0.756184  0.814086                      \n",
      "\n",
      "ensemble_ID: 557\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "afdc171d1cdd4ff6b003a8fd4abcc005",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Epoch', max=3), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "epoch      trn_loss   val_loss   accuracy                      \n",
      "    0      -0.746134  -0.700669  0.808389  \n",
      "    1      -0.947916  -0.748495  0.808389                      \n",
      "    2      -0.973677  -0.762684  0.810979                      \n",
      "   accuracy      mapk      model\n",
      "9  0.006732  0.004920     {lgbm}\n",
      "8  0.003625  0.003107   {r34_10}\n",
      "3  0.002071  0.001726    {xbg_3}\n",
      "4  0.001036  0.003539  {r_raw_1}\n",
      "5  0.001036  0.002071     {rx_7}\n",
      "0 -0.001554 -0.000345     {rx_9}\n",
      "2 -0.001554  0.000259     {rx_5}\n",
      "1 -0.002589  0.000432  {r34ev_3}\n",
      "6 -0.003107 -0.002762  {alex_16}\n",
      "7 -0.004661 -0.003194   {r34_15}\n"
     ]
    }
   ],
   "source": [
    "freesound_ensemble.model_importance(ensemble_ID, bs, lr, n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### View models in an ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 497,
   "metadata": {},
   "outputs": [],
   "source": [
    "ensemble_ID = 569"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 498,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alex_16',\n",
       " 'alex_6',\n",
       " 'catboost',\n",
       " 'lgbm',\n",
       " 'r34_10',\n",
       " 'r34_15',\n",
       " 'r34_5',\n",
       " 'r_10',\n",
       " 'r_22',\n",
       " 'r_raw_1',\n",
       " 'rx_13',\n",
       " 'rx_5',\n",
       " 'rx_7',\n",
       " 'rx_9',\n",
       " 'xbg_3'}"
      ]
     },
     "execution_count": 498,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "freesound_ensemble.view_models_in_ensemble(ensemble_ID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'lgbm', 'rx_5', 'r34_10', 'rx_9', 'r34_14', 'r_33', 'rx_13', 'rx_7',\n",
    "       'catboost', 'r34_5', 'r34_11', 'r34_15', 'r34_8', 'rx_2', 'r34_7',\n",
    "       'rx_11', 'r34_3', 'r34ev_3', 'rx_3', 'r_18', 'alex_16', 'r_15', 'r34_6',\n",
    "       'r_10', 'r_7', 'r_5', 'alex_6', 'r_6', 'r_2', 'r101_2', 'r_raw_1',\n",
    "       'r_22', 'r_30', 'r_4', 'r34_12', 'r34b_1', 'r_26', 'r31', 'r34b_2',\n",
    "       'xbg_1', 'xbg_2', 'xbg_3', 'rb_1', 'rb_2', 'rb_3'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Create a submission file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Submission saved to data/freesound/ensemble_files/submission_9.csv\n"
     ]
    }
   ],
   "source": [
    "ensemble_ID = 569\n",
    "name = 'submission_9.csv' \n",
    "\n",
    "freesound_ensemble.create_submission(ensemble_ID, name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 494,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9400"
      ]
     },
     "execution_count": 494,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "submission_df = pd.read_csv(PATH/f'ensemble_files/{name}')\n",
    "\n",
    "for idx, fname in bad_files_d.items():    \n",
    "    row = pd.DataFrame({\"fname\": fname, \"label\": 'Laughter Hi-Hat Flute'}, index=[idx])\n",
    "    submission_df = pd.concat([submission_df.iloc[:idx], row, submission_df.iloc[idx:]])\n",
    "\n",
    "submission_df.to_csv(PATH/f'ensemble_files/{name}', index=False)\n",
    "len(submission_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  },
  "toc": {
   "colors": {
    "hover_highlight": "#DAA520",
    "navigate_num": "#000000",
    "navigate_text": "#333333",
    "running_highlight": "#FF0000",
    "selected_highlight": "#FFD700",
    "sidebar_border": "#EEEEEE",
    "wrapper_background": "#FFFFFF"
   },
   "moveMenuLeft": true,
   "nav_menu": {
    "height": "86px",
    "width": "252px"
   },
   "navigate_menu": true,
   "number_sections": true,
   "sideBar": true,
   "threshold": 4,
   "toc_cell": false,
   "toc_section_display": "block",
   "toc_window_display": false,
   "widenNotebook": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
